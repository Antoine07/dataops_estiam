---
marp: true
theme: default
paginate: true
size: 16:9
---

#  TP : Organiser un Sprint DataOps avec Scrum  

---

## Contexte gÃ©nÃ©ral

Vous faites partie de l'Ã©quipe **Data** dâ€™une entreprise qui souhaite **suivre les performances scolaires des Ã©tudiants** afin dâ€™alimenter un **tableau de bord analytique**.

Lâ€™objectif est de simuler un **Sprint Scrum complet** sans Ã©crire de code, autour de la mise en place dâ€™un **pipeline de donnÃ©es automatisÃ©** pour :

1. TÃ©lÃ©charger le dataset depuis **Kaggle**,  
2. Nettoyer et transformer les donnÃ©es,  
3. Charger les donnÃ©es dans **PostgreSQL**.

>  **Dataset :** [Students Performance Dataset](https://www.kaggle.com/datasets/rabieelkharoua/students-performance-dataset)  
> Contient des informations sur : sexe, origine, niveau parental, et scores en mathÃ©matiques, lecture et Ã©criture.

---

##  Organisation du travail sur GitHub

Tout le travail de ce TP se fait sur **GitHub** :  
vous allez simuler un vrai sprint Scrum avec backlog, issues et Kanban.

### Ã‰tapes :
1. CrÃ©ez un **repository GitHub** pour votre Ã©quipe.  
2. Dans lâ€™onglet **Projects**, crÃ©ez un tableau *Kanban*.  
3. CrÃ©ez une **issue par User Story**.  
4. Utilisez les **labels** (`To do`, `In progress`, `Done`) pour suivre lâ€™avancement.  
5. Des **vidÃ©os explicatives** sont disponibles dans **Teams â†’ Fichiers / VidÃ©os**.

---

##  Composition de lâ€™Ã©quipe

| RÃ´le | ResponsabilitÃ© principale |
|------|----------------------------|
| **Data Engineer** | Extraction et transformation des donnÃ©es |
| **Data Analyst** | Analyse et comprÃ©hension des donnÃ©es |
| **DataOps Engineer** | Automatisation et orchestration du pipeline |
| **Scrum Master** | Suivi du cadre Scrum et facilitation |
| *(Optionnel)* **Product Owner / Coach** | Priorisation du backlog et suivi mÃ©tier |

---

##  Ã‰tape 1 â€” Lecture du Backlog

Chaque Ã©quipe identifie les **User Stories (US)** du sprint :

| ID  | User Story | PrioritÃ© |
| --- | ----------- | -------- |
| US1 | En tant que *Data Engineer*, je veux **automatiser le tÃ©lÃ©chargement Kaggle** pour standardiser la collecte. | Haute |
| US2 | En tant que *Data Engineer*, je veux **nettoyer et standardiser les colonnes** pour garantir la qualitÃ©. | Haute |
| US3 | En tant que *DataOps Engineer*, je veux **charger automatiquement les donnÃ©es dans PostgreSQL**. | Haute |
| US4 | En tant que *Data Analyst*, je veux **vÃ©rifier les distributions et anomalies** des donnÃ©es. | Moyenne |
| US5 | En tant que *Scrum Master*, je veux **suivre la progression via GitHub Kanban**. | Moyenne |

---

##  Ã‰tape 2 â€” DÃ©tail des tÃ¢ches

Pour chaque User Story, dÃ©finissez les **tÃ¢ches techniques** correspondantes :

| TÃ¢ches | Description |
| ------- | ------------ |
| Configurer la clÃ© Kaggle | Permet lâ€™accÃ¨s Ã  lâ€™API Kaggle pour le tÃ©lÃ©chargement. |
| TÃ©lÃ©charger le dataset | Script ou commande pour rÃ©cupÃ©rer le CSV brut. |
| Nettoyage des donnÃ©es | GÃ©rer valeurs manquantes, normaliser les colonnes. |
| Transformation des donnÃ©es | CrÃ©er de nouvelles colonnes (ex. moyenne des scores). |
| Chargement PostgreSQL | InsÃ©rer les donnÃ©es dans la base. |
| Tests pipeline | VÃ©rifier la cohÃ©rence des Ã©tapes. |
| Documentation | Expliquer le fonctionnement du pipeline. |
| Reporting initial | Visualiser les distributions et anomalies. |
| Suivi Kanban / issues | Mettre Ã  jour les statuts dans GitHub Project. |

---

##  Ã‰tape 3 â€” Estimation (Story Points)

Chaque tÃ¢che est estimÃ©e selon la **complexitÃ©**, Ã  lâ€™aide du **Planning Poker**.

| Valeur | Signification |
| ------- | -------------- |
| 1 | TrÃ¨s simple |
| 2 | Simple |
| 3 | Moyenne |
| 5 | Difficile |
| 8 | TrÃ¨s difficile |
| 13 | Complexe / RisquÃ© |

> ğŸ”¢ BasÃ© sur la **suite de Fibonacci** : permet dâ€™estimer la charge sans entrer dans le temps prÃ©cis.

---

##  Ã‰tape 4 â€” Planification du Sprint

* SÃ©lectionnez les tÃ¢ches **rÃ©alisables en un sprint (1 semaine)**.  
* RÃ©partissez-les entre les membres.  
* CrÃ©ez votre **Sprint Backlog** dans GitHub Project.

| TÃ¢che | Responsable | Estimation | Livrable attendu |
|-------|--------------|-------------|------------------|
| TÃ©lÃ©charger le dataset | Data Engineer | 3 pts | CSV brut tÃ©lÃ©chargÃ© |
| Nettoyer les donnÃ©es | Data Engineer | 5 pts | CSV nettoyÃ© |
| Transformation des donnÃ©es | Data Engineer | 5 pts | CSV transformÃ© |
| Charger PostgreSQL | DataOps | 5 pts | DonnÃ©es dans la DB |
| Tests pipeline | DataOps | 3 pts | Rapport de tests |
| Analyse exploratoire | Data Analyst | 3 pts | Rapport initial |
| Documentation | Tous | 2 pts | README pipeline |
| Suivi Kanban / issues | Scrum Master | 2 pts | Board Ã  jour |

---

##  Ã‰tape 5 â€” Ã‰vÃ©nements Scrum Ã  simuler

| Ã‰vÃ©nement | Objectif | DurÃ©e indicative |
|------------|-----------|------------------|
| **Sprint Planning** | DÃ©finir les prioritÃ©s et les tÃ¢ches | 1h |
| **Daily Scrum** | Synchroniser lâ€™Ã©quipe (stand-up) | 10 min |
| **Sprint Review** | PrÃ©senter les rÃ©sultats du sprint | 30 min |
| **Sprint Retrospective** | Identifier les points Ã  amÃ©liorer | 30 min |

> ğŸ’¬ Simulez ces rÃ©unions Ã  lâ€™oral ou Ã  lâ€™Ã©crit dans Teams ou GitHub Discussions.

---

## Ã‰tape 6 â€” Bilan du Sprint

Ã€ la fin du sprint, lâ€™Ã©quipe rÃ©pond Ã  trois questions :

1. âœ… Quâ€™est-ce qui a bien fonctionnÃ© ?  
2. âš ï¸ Quâ€™est-ce qui aurait pu mieux se passer ?  
3. ğŸš€ Que va-t-on amÃ©liorer pour le prochain sprint ?

ğŸ¯ Objectif : **amÃ©lioration continue** et esprit dâ€™Ã©quipe.

---

##  Livrables attendus

1. Un **repository GitHub** par Ã©quipe contenant :
   - Un `README.md` documentant votre organisation Scrum.  
   - Un **tableau GitHub Project** avec backlog et sprint.  
   - Des **issues** correspondant aux User Stories.
2. Un **compte rendu de sprint** (Review + RÃ©trospective) ajoutÃ© au README.  
3. *(Optionnel)* Une **capture du Kanban final** Ã  la fin du sprint.

---

## Fin du TP

Vous aurez simulÃ© un **Sprint Scrum complet appliquÃ© Ã  un projet DataOps rÃ©el**.  

> â€œInspecter, adapter et livrer de la valeur â€” mÃªme dans la donnÃ©e.â€  
